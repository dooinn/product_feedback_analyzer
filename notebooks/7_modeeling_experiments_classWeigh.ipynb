{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a257ef59",
   "metadata": {},
   "source": [
    "# 7. ClassWeigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53333c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimdo\\anaconda3\\envs\\yt_nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datasets import Dataset\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065bc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned.csv\")\n",
    "df = df[[\"comment\", \"label_encoded\"]].rename(columns={\"comment\": \"text\", \"label_encoded\": \"label\"})\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ebd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ExperimentRunner:\n",
    "\n",
    "    def __init__(self, train_ds, test_ds, num_labels=6, experiment_name=\"YouTubeCommentClassifier\"):\n",
    "        \"\"\"\n",
    "        Initialize Experiment Runner with datasets and MLflow setup.\n",
    "        \"\"\"\n",
    "        self.train_ds = train_ds\n",
    "        self.test_ds = test_ds\n",
    "        self.num_labels = num_labels\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    def compute_metrics(self, pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\"accuracy\": acc}\n",
    "\n",
    "    def _tokenize(self, batch):\n",
    "        return self.tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "    def train_and_evaluate(self, model_name, learning_rate=2e-5, batch_size=8, num_epochs=5, patience=2):\n",
    "        \"\"\"\n",
    "        Train, evaluate, and log an experiment to MLflow.\n",
    "        \"\"\"\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "        print(f\"\\nðŸš€ Running experiment: {model_name} | LR={learning_rate} | BS={batch_size}\")\n",
    "\n",
    "        experiment_dir = f\"../experiment_results/{model_name.replace('/', '_')}_lr{learning_rate}_bs{batch_size}_ep{num_epochs}\"\n",
    "        os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=self.num_labels)\n",
    "\n",
    "\n",
    "        train_enc = self.train_ds.map(self._tokenize, batched=True)\n",
    "        test_enc = self.test_ds.map(self._tokenize, batched=True)\n",
    "        train_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "        test_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "        labels = [int(x) for x in self.train_ds[\"label\"]]\n",
    "        class_counts = torch.bincount(torch.tensor(labels))\n",
    "        total_samples = float(sum(class_counts))\n",
    "        class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "        class_weights = class_weights.to(torch.float32)\n",
    "        print(\"Class weights:\", class_weights.tolist())\n",
    "\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=experiment_dir,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=num_epochs,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            logging_dir=\"./logs\",\n",
    "            logging_steps=50,\n",
    "        )\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        #  Custom Trainer with Weighted Loss\n",
    "        # ---------------------------------------------------------\n",
    "        class WeightedTrainer(Trainer):\n",
    "            def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "                labels = inputs.get(\"labels\")\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.get(\"logits\")\n",
    "                loss_fct = CrossEntropyLoss(weight=class_weights.to(model.device))\n",
    "                loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "                return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # Training and evaluation with MLflow logging\n",
    "        # ---------------------------------------------------------\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_lr{learning_rate}_bs{batch_size}\"):\n",
    "\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "            mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "            mlflow.log_param(\"batch_size\", batch_size)\n",
    "            mlflow.log_param(\"epochs\", num_epochs)\n",
    "            mlflow.log_param(\"patience\", patience)\n",
    "            mlflow.log_param(\"class_weights\", class_weights.tolist())\n",
    "\n",
    "            trainer = WeightedTrainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_enc,\n",
    "                eval_dataset=test_enc,\n",
    "                tokenizer=self.tokenizer,\n",
    "                compute_metrics=self.compute_metrics,\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=patience)],\n",
    "            )\n",
    "\n",
    "            trainer.train()\n",
    "            results = trainer.evaluate()\n",
    "\n",
    "            for k, v in results.items():\n",
    "                mlflow.log_metric(k, v)\n",
    "\n",
    "            # -----------------------------------------------------\n",
    "            # Evaluation & Visualization\n",
    "            # -----------------------------------------------------\n",
    "            print(\"Generating classification report and confusion matrix ...\")\n",
    "            preds_output = trainer.predict(test_enc)\n",
    "            y_true = preds_output.label_ids\n",
    "            y_pred = preds_output.predictions.argmax(-1)\n",
    "\n",
    "            report = classification_report(y_true, y_pred, digits=3)\n",
    "            report_path = os.path.join(\n",
    "                experiment_dir,\n",
    "                f\"classification_report_{model_name.replace('/', '_')}_lr{learning_rate}_bs{batch_size}_ep{num_epochs}.txt\",\n",
    "            )\n",
    "            with open(report_path, \"w\") as f:\n",
    "                f.write(report)\n",
    "            mlflow.log_artifact(report_path)\n",
    "\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.title(f\"{model_name} Confusion Matrix\")\n",
    "            cm_path = os.path.join(\n",
    "                experiment_dir,\n",
    "                f\"confusion_matrix_{model_name.replace('/', '_')}_lr{learning_rate}_bs{batch_size}_ep{num_epochs}.png\",\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(cm_path)\n",
    "            mlflow.log_artifact(cm_path)\n",
    "            plt.close()\n",
    "\n",
    "            history = pd.DataFrame(trainer.state.log_history)\n",
    "            train_loss = history[history[\"loss\"].notna()][[\"epoch\", \"loss\"]]\n",
    "            eval_loss = history[history[\"eval_loss\"].notna()][[\"epoch\", \"eval_loss\"]]\n",
    "\n",
    "            if not train_loss.empty and not eval_loss.empty:\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                plt.plot(train_loss[\"epoch\"], train_loss[\"loss\"], marker=\"o\", label=\"Training Loss\")\n",
    "                plt.plot(eval_loss[\"epoch\"], eval_loss[\"eval_loss\"], marker=\"s\", label=\"Validation Loss\")\n",
    "                plt.legend()\n",
    "                plt.title(f\"{model_name} - LR={learning_rate}\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.tight_layout()\n",
    "                plot_path = os.path.join(\n",
    "                    experiment_dir,\n",
    "                    f\"loss_curve_{model_name.replace('/', '_')}_lr{learning_rate}_bs{batch_size}_ep{num_epochs}.png\",\n",
    "                )\n",
    "                plt.savefig(plot_path)\n",
    "                mlflow.log_artifact(plot_path)\n",
    "                plt.close()\n",
    "\n",
    "        print(f\"âœ… Experiment complete. Results saved in: {experiment_dir}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd01ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Running experiment: distilbert-base-uncased | LR=2e-05 | BS=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 15454.91 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 16197.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 01:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.602700</td>\n",
       "      <td>1.128897</td>\n",
       "      <td>0.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.900500</td>\n",
       "      <td>0.817178</td>\n",
       "      <td>0.801370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.767462</td>\n",
       "      <td>0.832192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.431700</td>\n",
       "      <td>0.774277</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>0.793900</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/distilbert-base-uncased_lr2e-05_bs8_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: distilbert-base-uncased | LR=2e-05 | BS=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 13896.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 15686.27 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 01:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.773100</td>\n",
       "      <td>1.527799</td>\n",
       "      <td>0.623288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.518500</td>\n",
       "      <td>1.073106</td>\n",
       "      <td>0.743151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.906663</td>\n",
       "      <td>0.787671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.749300</td>\n",
       "      <td>0.829218</td>\n",
       "      <td>0.797945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.581100</td>\n",
       "      <td>0.809393</td>\n",
       "      <td>0.811644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/distilbert-base-uncased_lr2e-05_bs16_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: distilbert-base-uncased | LR=3e-05 | BS=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 16102.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 13886.85 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 01:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.531800</td>\n",
       "      <td>1.041089</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>0.816369</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.923104</td>\n",
       "      <td>0.828767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.876703</td>\n",
       "      <td>0.845890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.965678</td>\n",
       "      <td>0.852740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/distilbert-base-uncased_lr3e-05_bs8_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: distilbert-base-uncased | LR=3e-05 | BS=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 13481.00 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 10281.45 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 01:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.744200</td>\n",
       "      <td>1.318795</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.329500</td>\n",
       "      <td>0.891420</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.829569</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.514100</td>\n",
       "      <td>0.757475</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.761806</td>\n",
       "      <td>0.852740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/distilbert-base-uncased_lr3e-05_bs16_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: bert-base-uncased | LR=2e-05 | BS=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 10405.75 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 10069.28 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 02:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.715400</td>\n",
       "      <td>1.399238</td>\n",
       "      <td>0.715753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.049300</td>\n",
       "      <td>0.884895</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.866450</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.901725</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/bert-base-uncased_lr2e-05_bs8_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: bert-base-uncased | LR=2e-05 | BS=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 9560.93 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 9636.16 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 02:08, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.790400</td>\n",
       "      <td>1.696372</td>\n",
       "      <td>0.592466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.638000</td>\n",
       "      <td>1.274909</td>\n",
       "      <td>0.681507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.921324</td>\n",
       "      <td>0.797945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.823305</td>\n",
       "      <td>0.797945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.786503</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/bert-base-uncased_lr2e-05_bs16_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: bert-base-uncased | LR=3e-05 | BS=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 7019.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 8372.21 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 02:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.616200</td>\n",
       "      <td>1.098233</td>\n",
       "      <td>0.787671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>0.814884</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>0.929977</td>\n",
       "      <td>0.825342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>1.052430</td>\n",
       "      <td>0.832192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>1.083010</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/bert-base-uncased_lr3e-05_bs8_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: bert-base-uncased | LR=3e-05 | BS=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 10768.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 9055.62 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 02:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.773700</td>\n",
       "      <td>1.567793</td>\n",
       "      <td>0.599315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.499200</td>\n",
       "      <td>0.864421</td>\n",
       "      <td>0.791096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>0.755791</td>\n",
       "      <td>0.801370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.700072</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.723120</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/bert-base-uncased_lr3e-05_bs16_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: roberta-base | LR=2e-05 | BS=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 10748.97 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 10172.57 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 02:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.695300</td>\n",
       "      <td>0.887080</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.663239</td>\n",
       "      <td>0.804795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.933344</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.360900</td>\n",
       "      <td>0.894732</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>0.921850</td>\n",
       "      <td>0.828767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/roberta-base_lr2e-05_bs8_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: roberta-base | LR=2e-05 | BS=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 11590.13 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 10677.00 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 02:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.798200</td>\n",
       "      <td>1.467897</td>\n",
       "      <td>0.541096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.431000</td>\n",
       "      <td>0.726715</td>\n",
       "      <td>0.804795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.773840</td>\n",
       "      <td>0.791096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443800</td>\n",
       "      <td>0.781594</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.769629</td>\n",
       "      <td>0.828767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/roberta-base_lr2e-05_bs16_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: roberta-base | LR=3e-05 | BS=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 13064.31 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 10387.05 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 02:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.439000</td>\n",
       "      <td>0.913247</td>\n",
       "      <td>0.818493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.780100</td>\n",
       "      <td>0.719089</td>\n",
       "      <td>0.797945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>1.087525</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>1.113416</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>1.204846</td>\n",
       "      <td>0.845890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/roberta-base_lr3e-05_bs8_ep5\n",
      "\n",
      "\n",
      "ðŸš€ Running experiment: roberta-base | LR=3e-05 | BS=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1165/1165 [00:00<00:00, 10989.98 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 9983.51 examples/s]\n",
      "C:\\Users\\kimdo\\AppData\\Local\\Temp\\ipykernel_19640\\1532451395.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [2.0656027793884277, 1.981292486190796, 1.5051679611206055, 0.26203328371047974, 3.883333444595337, 3.6635220050811768]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 02:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.779700</td>\n",
       "      <td>1.019580</td>\n",
       "      <td>0.664384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.145700</td>\n",
       "      <td>0.735620</td>\n",
       "      <td>0.787671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.424100</td>\n",
       "      <td>0.757684</td>\n",
       "      <td>0.760274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>0.788700</td>\n",
       "      <td>0.839041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.814869</td>\n",
       "      <td>0.839041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classification report and confusion matrix ...\n",
      "âœ… Experiment complete. Results saved in: ../experiment_results/roberta-base_lr3e-05_bs16_ep5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\"distilbert-base-uncased\", \"bert-base-uncased\", \"roberta-base\"]\n",
    "\n",
    "learning_rates = [2e-5, 3e-5]\n",
    "batch_sizes = [8, 16]\n",
    "epochs = [5]\n",
    "runner = ExperimentRunner(train_ds, test_ds)\n",
    "for model_name, lr, bs, ep in itertools.product(models, learning_rates, batch_sizes, epochs):\n",
    "    runner.train_and_evaluate(model_name, learning_rate=lr, batch_size=bs, num_epochs=ep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e35f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Loading model from: ../experiment_results/bert-base-uncased_lr2e-05_bs8_ep5/checkpoint-730\n",
      "âœ… Model and tokenizer successfully saved â†’ ../experiment_results/final_model\\final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../experiment_results/bert-base-uncased_lr2e-05_bs8_ep5/checkpoint-730\"\n",
    "\n",
    "output_dir = \"../final_model\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "pickle_path = os.path.join(output_dir, \"final_model.pkl\")\n",
    "with open(pickle_path, \"wb\") as f:\n",
    "    pickle.dump({\"model\": model, \"tokenizer\": tokenizer}, f)\n",
    "\n",
    "print(f\"Model and tokenizer successfully saved â†’ {pickle_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
